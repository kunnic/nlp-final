{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d154d067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.3\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3bff567",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8970d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Third party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "\n",
    "# Local application imports\n",
    "\n",
    "# Constants\n",
    "data_path = \"./data/toxic.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ce54a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (28942, 3)\n",
      "==================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28942 entries, 0 to 28941\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   text        28942 non-null  object\n",
      " 1   label       28942 non-null  int64 \n",
      " 2   word_count  28942 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 678.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv(data_path)\n",
    "shape = data.shape\n",
    "print(f\"Dataset shape: {shape}\\n\" + ('=' * 50))\n",
    "\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29a284a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling\n",
    "data_copy = data.copy()\n",
    "\n",
    "toxic_len = len(data_copy[data_copy['label'] == 1])\n",
    "\n",
    "toxic = data_copy[data_copy['label'] == 1]\n",
    "non_toxic = data_copy[data_copy['label'] == 0].sample(n = toxic_len, random_state = 42)\n",
    "\n",
    "balanced = pd.concat([toxic, non_toxic], ignore_index = True)\n",
    "balanced = balanced.sample(frac = 1, random_state = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6d540fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10870 entries, 0 to 10869\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   text        10870 non-null  object\n",
      " 1   label       10870 non-null  int64 \n",
      " 2   word_count  10870 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 254.9+ KB\n"
     ]
    }
   ],
   "source": [
    "balanced.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "942b8eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, validation_set = train_test_split(\n",
    "    balanced,\n",
    "    test_size= 0.1,\n",
    "    random_state= 1,\n",
    "    stratify = balanced['label']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "317cd36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1524586",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_set)\n",
    "val_dataset = Dataset.from_pandas(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2b46257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 9783/9783 [00:02<00:00, 4038.86 examples/s]\n",
      "Map: 100%|██████████| 1087/1087 [00:00<00:00, 5128.94 examples/s]\n"
     ]
    }
   ],
   "source": [
    "process = lambda batch: tokenizer(\n",
    "    batch[\"text\"],\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    max_length=256,\n",
    ")\n",
    "\n",
    "train_tokenized = train_dataset.map(\n",
    "    process,\n",
    "    batched=True,\n",
    ")\n",
    "\n",
    "validation_tokenized = val_dataset.map(\n",
    "    process,\n",
    "    batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "171b8868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"vinai/phobert-base\",\n",
    "    num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccd0b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(prediction: tuple) -> dict:\n",
    "    predict_label, true_label = prediction\n",
    "    predict_label = np.argmax(predict_label, axis=1)\n",
    "\n",
    "    f1 = f1_score(true_label, predict_label, average='weighted')\n",
    "    accuracy = accuracy_score(true_label, predict_label)\n",
    "    precision = precision_score(true_label, predict_label, average='weighted')\n",
    "    recall = recall_score(true_label, predict_label, average='weighted')\n",
    "\n",
    "    return {\n",
    "        'f1': f1,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eaf0863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./phobert_toxic_result\",\n",
    "\n",
    "    per_device_train_batch_size=2,  \n",
    "    gradient_accumulation_steps=16, \n",
    "    fp16=True,                      \n",
    "   \n",
    "    num_train_epochs=5,             \n",
    "    learning_rate=3e-5,             \n",
    "    \n",
    "    eval_strategy=\"epoch\",    \n",
    "    save_strategy=\"epoch\",          \n",
    "    load_best_model_at_end=True,    \n",
    "    metric_for_best_model=\"f1\",     \n",
    "   \n",
    "    logging_steps=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01052705",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=validation_tokenized,\n",
    "    compute_metrics=evaluation,\n",
    "    processing_class=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d77a6908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1530' max='1530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1530/1530 31:07, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.354300</td>\n",
       "      <td>0.434864</td>\n",
       "      <td>0.810393</td>\n",
       "      <td>0.811408</td>\n",
       "      <td>0.818105</td>\n",
       "      <td>0.811408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.273800</td>\n",
       "      <td>0.417360</td>\n",
       "      <td>0.830719</td>\n",
       "      <td>0.830727</td>\n",
       "      <td>0.830801</td>\n",
       "      <td>0.830727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.203200</td>\n",
       "      <td>0.493580</td>\n",
       "      <td>0.827517</td>\n",
       "      <td>0.827967</td>\n",
       "      <td>0.831345</td>\n",
       "      <td>0.827967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.566849</td>\n",
       "      <td>0.842606</td>\n",
       "      <td>0.842686</td>\n",
       "      <td>0.843420</td>\n",
       "      <td>0.842686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>0.643571</td>\n",
       "      <td>0.838065</td>\n",
       "      <td>0.838086</td>\n",
       "      <td>0.838248</td>\n",
       "      <td>0.838086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1530, training_loss=0.19951781743492175, metrics={'train_runtime': 1870.221, 'train_samples_per_second': 26.155, 'train_steps_per_second': 0.818, 'total_flos': 6435038636467200.0, 'train_loss': 0.19951781743492175, 'epoch': 5.0})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "deeaa169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0cba0bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "token = os.getenv(\"HUGGINGFACE_HUB_TOKEN\")\n",
    "if not token:\n",
    "    raise RuntimeError(\"HUGGINGFACE_HUB_TOKEN not found in .env\")\n",
    "\n",
    "os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = token\n",
    "\n",
    "try:\n",
    "    login(token=token)\n",
    "except Exception as e:\n",
    "    print(\"huggingface_hub.login() warning:\", e)\n",
    "\n",
    "\n",
    "splits = {'train': 'train.csv', 'validation': 'dev.csv', 'test': 'test.csv'}\n",
    "vi_hsd = [pd.read_csv(\"hf://datasets/sonlam1102/vihsd/\" + splits[split]) for split in splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ee4fd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6680/6680 [00:01<00:00, 4776.94 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang đánh giá trên tập Test...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- KẾT QUẢ BASELINE V1 (PHOBERT) ---\n",
      "{'test_loss': 0.450543612241745, 'test_f1': 0.8156071080119192, 'test_accuracy': 0.7961077844311377, 'test_precision': 0.8610184689422915, 'test_recall': 0.7961077844311377, 'test_runtime': 59.6863, 'test_samples_per_second': 111.918, 'test_steps_per_second': 13.99}\n"
     ]
    }
   ],
   "source": [
    "for each in vi_hsd:\n",
    "    each.rename(columns={'free_text': 'text', 'label_id': 'label'}, inplace=True)\n",
    "    each['label'] = each['label'].replace(2, 1)\n",
    "\n",
    "test_df = vi_hsd[2]\n",
    "\n",
    "test_dataset = Dataset.from_pandas(test_df) \n",
    "tokenized_test = test_dataset.map(\n",
    "    lambda p: tokenizer(p['text'], truncation=True, padding='max_length', max_length=256),\n",
    "    batched=True\n",
    ")\n",
    "\n",
    "# 2. Chạy dự đoán\n",
    "print(\"Đang đánh giá trên tập Test...\")\n",
    "test_results = trainer.predict(tokenized_test)\n",
    "\n",
    "# 3. In ra kết quả V1\n",
    "print(\"--- KẾT QUẢ BASELINE V1 (PHOBERT) ---\")\n",
    "print(test_results.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "584ab28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6680/6680 [00:01<00:00, 3977.30 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang đánh giá trên tập Test...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- KẾT QUẢ BASELINE V1 (PHOBERT) ---\n",
      "{'test_loss': 0.5575075745582581, 'test_f1': 0.8522600834227863, 'test_accuracy': 0.8410179640718562, 'test_precision': 0.875531916317784, 'test_recall': 0.8410179640718562, 'test_runtime': 44.6553, 'test_samples_per_second': 149.59, 'test_steps_per_second': 18.699}\n"
     ]
    }
   ],
   "source": [
    "for each in vi_hsd:\n",
    "    each.rename(columns={'free_text': 'text', 'label_id': 'label'}, inplace=True)\n",
    "    each['label'] = each['label'].replace(2, 1)\n",
    "\n",
    "test_df = vi_hsd[2]\n",
    "\n",
    "test_dataset = Dataset.from_pandas(test_df) \n",
    "tokenized_test = test_dataset.map(\n",
    "    lambda p: tokenizer(p['text'], truncation=True, padding='max_length', max_length=256),\n",
    "    batched=True\n",
    ")\n",
    "\n",
    "# 2. Chạy dự đoán\n",
    "print(\"Đang đánh giá trên tập Test...\")\n",
    "test_results = trainer.predict(tokenized_test)\n",
    "\n",
    "# 3. In ra kết quả V1\n",
    "print(\"--- KẾT QUẢ BASELINE V1 (PHOBERT) ---\")\n",
    "print(test_results.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2628514",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = data.copy()\n",
    "\n",
    "toxic_new_politics = pd.read_csv(\"politics_processed.csv\")\n",
    "toxic_new_offensive = pd.read_csv(\"offensive_processed.csv\")\n",
    "toxic_new_racist = pd.read_csv(\"racist_processed.csv\")\n",
    "\n",
    "data_new = pd.concat([data_new, toxic_new_politics, toxic_new_offensive, toxic_new_racist], ignore_index=True)\n",
    "data_new = data_new.sample(frac=1, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "912c25d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    24102\n",
       "0    23507\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4835ef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, validation_set = train_test_split(\n",
    "    data_new,\n",
    "    test_size= 0.1,\n",
    "    random_state= 1,\n",
    "    stratify = data_new['label']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
